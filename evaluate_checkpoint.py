import os
import torch
from omegaconf import OmegaConf

# å¯¼å…¥æ‚¨é¡¹ç›®ä¸­çš„ç›¸å…³æ¨¡å—
from trainers.test import test
from utils.utils import re_prepend_paths

# å¯¼å…¥å¹¶ç¦ç”¨ wandb
import wandb
wandb.init(mode="disabled")
from pytorch_lightning.loggers import WandbLogger

# --- 1. é…ç½®åŒºåŸŸï¼šè¯·åœ¨è¿™é‡Œå¡«å†™æ‚¨çš„è·¯å¾„ ---

# æŒ‡å®šæ‚¨è¦è¯„æµ‹çš„ã€å·²ç»è®­ç»ƒå®Œæˆçš„ checkpoint æ–‡ä»¶è·¯å¾„
# !! è¯·ç¡®ä¿ä½¿ç”¨çš„æ˜¯æˆ‘ä»¬ä¹‹å‰ç”¨ update_checkpoint.py ç”Ÿæˆçš„ _updated.ckpt æˆ– _final.ckpt æ–‡ä»¶ !!
CHECKPOINT_PATH = "/data0/jiazy/tab-image-bench/MMCL2/checkpoint_last_epoch_499_final.ckpt"

# æŒ‡å®šæ•°æ®é›†çš„æ ¹ç›®å½•
BASE_DATA_DIR = "/data1/jiazy/tab_image_bench/PetFinder_datasets/dataset"

# --- é…ç½®ç»“æŸ ---


def evaluate_from_checkpoint():
    """
    ä¸€ä¸ªä¸“é—¨ç”¨äºåŠ è½½ checkpoint å¹¶è¿›è¡Œæµ‹è¯•çš„å‡½æ•°ã€‚
    """
    print(f"===== å¼€å§‹ä» Checkpoint è¿›è¡Œè¯„æµ‹ =====")

    # --- æ­¥éª¤ 1: åŠ è½½ Checkpoint å’Œé…ç½® ---
    if not os.path.exists(CHECKPOINT_PATH):
        print(f"âŒ é”™è¯¯: Checkpoint æ–‡ä»¶æœªæ‰¾åˆ°: {CHECKPOINT_PATH}")
        return

    print(f"[*] æ­£åœ¨åŠ è½½ Checkpoint: {CHECKPOINT_PATH}")
    ckpt = torch.load(CHECKPOINT_PATH, map_location="cpu")
    
    if 'hyper_parameters' not in ckpt:
        print("âŒ é”™è¯¯: åœ¨ checkpoint ä¸­æœªæ‰¾åˆ° 'hyper_parameters'ã€‚")
        return
        
    args = OmegaConf.create(ckpt['hyper_parameters'])
    print("[*] å·²æˆåŠŸä» Checkpoint ä¸­åŠ è½½é…ç½® (hparams)ã€‚")

    # --- æ­¥éª¤ 2: ä¸´æ—¶è§£é”é…ç½®ç»“æ„ï¼Œå¹¶æ›´æ–°è¯„æµ‹æ‰€éœ€å‚æ•° ---
    print("[*] ä¸´æ—¶è§£é”é…ç½® 'struct' æ¨¡å¼ä»¥è¿›è¡Œä¿®æ”¹...")
    OmegaConf.set_struct(args, False)

    # ç°åœ¨å¯ä»¥å®‰å…¨åœ°æ·»åŠ æˆ–ä¿®æ”¹é…ç½®äº†
    args.checkpoint = CHECKPOINT_PATH
    args.resume_training = False
    args.pretrain = False
    args.test = True
    args.data_db = BASE_DATA_DIR # <-- ç°åœ¨è¿™ä¸€è¡Œå¯ä»¥æˆåŠŸæ‰§è¡Œäº†

    # (å¯é€‰) ä¿®æ”¹å®Œæˆåï¼Œå»ºè®®é‡æ–°é”å®šç»“æ„
    OmegaConf.set_struct(args, True)
    print("[*] é…ç½®å·²æ›´æ–°å¹¶é‡æ–°é”å®šã€‚")
    
    # --- æ­¥éª¤ 3: ä¿®æ­£é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰æ•°æ®è·¯å¾„ ---
    print("[*] æ­£åœ¨è°ƒç”¨ re_prepend_paths æ¥ä¿®æ­£æ–‡ä»¶è·¯å¾„...")
    args = re_prepend_paths(args)
    print("[*] æ–‡ä»¶è·¯å¾„ä¿®æ­£å®Œæˆã€‚")
    
    print("\n--- æ£€æŸ¥ä¿®æ­£åçš„å…³é”®è·¯å¾„ ---")
    print(f"  - å›¾åƒæµ‹è¯•é›†: {args.get('data_test_eval_imaging', 'æœªæ‰¾åˆ°')}")
    print(f"  - æ ‡ç­¾æµ‹è¯•é›†: {args.get('labels_test_eval_imaging', 'æœªæ‰¾åˆ°')}")
    print("----------------------------\n")

    # --- æ­¥éª¤ 4: åˆ›å»ºç¦»çº¿ Logger å¹¶è°ƒç”¨ test å‡½æ•° ---
    wandb_logger = WandbLogger(project="evaluation", offline=True)
    
    print("[*] æ‰€æœ‰å‡†å¤‡å·¥ä½œå®Œæˆï¼Œæ­£åœ¨è°ƒç”¨ test() å‡½æ•°...")
    test(args, wandb_logger, model=None)
    
    print("\nğŸ‰ è¯„æµ‹æµç¨‹å·²å®Œæˆï¼ ğŸ‰")


if __name__ == "__main__":
    evaluate_from_checkpoint()